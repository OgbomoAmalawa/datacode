---
title: "Machine Learning and Data Modelling"
author: "OGBOMO O AMALAWA"
date: "26/05/2020"
output: html_document
---

```{r}
##### Cross Validation Demo: Classification using K Nearest Neighbors --------------------

AIBLSelect <- read.csv("C:/Users/aoogb/Desktop/AIBLSelect.csv", stringsAsFactors = TRUE)
AIBLSelect

# Step 2: Explore the data, e.g. examine the structure of the AIBLSelect data frame, normalisation, and so on
str(AIBLSelect)


# table of diagnosis (We ignore data balancing process)
table(AIBLSelect$DXCURREN)
AIBLSelect$DXCURREN
# recode diagnosis as a factor
AIBLSelect$DXCURREN<- as.factor(AIBLSelect$DXCURREN)
str(AIBLSelect)
str(AIBLSelect$DXCURREN)
AIBLSelect




# table or proportions with more informative labels
round(prop.table(table(AIBLSelect$DXCURREN)) * 100, digits = 1)
str(AIBLSelect$DXCURREN)
# summarize three numeric features

# create normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
#Normalize data

# normalize the wbcd data
data_n <- as.data.frame(lapply(AIBLSelect[2:9], normalize))
data_n$DXCURREN<-AIBLSelect$DXCURREN

# confirm that normalization worked
summary(data_n$area_mean)

# Step 3: Split the data into developing subset (including training and validation subset) and testing subset
# pick up Healthy_Control subset and Non_Healthy_Control subset
Healthy_Control <- data_n[(data_n$DXCURREN == 1), ]
Non_Healthy_Control<- data_n[(data_n$DXCURREN == 0), ]
Healthy_Control
Non_Healthy_Control

# create developing subset (80%) and testing subset (20%) in terms of Healthy_Control and Non_Healthy_Control respectively
smp1 <- floor(nrow(Healthy_Control)*4/5)
smp0 <- floor(nrow(Non_Healthy_Control)*4/5)
smp1
smp0
set.seed(1)
# Randomly generate smp1 indices for Healthy_Control subset
idx1 <- sample(seq_len(nrow(Healthy_Control)), size = smp1) 
Healthy_Control_deve <- Healthy_Control[idx1, ]
Healthy_Control_test <-Healthy_Control[-idx1, ]

set.seed(0)
# Randomly generate smp0 indices for Non_Healthy_Control subset
idx0 <- sample(seq_len(nrow(Non_Healthy_Control)), size = smp0) 
Non_Healthy_Control_deve <- Non_Healthy_Control[idx0, ]
Non_Healthy_Control_test <- Non_Healthy_Control[-idx0, ]

# Combine Healthy_Control_test and Non_Healthy_Control_test by rows as TestingSubset, which will be used to test the validated classifier
TestingSubset <- rbind(Healthy_Control_test, Non_Healthy_Control_test )

# Set 9/10 of the developing subset to be training subset
# the remaining 1/10 of the developing subset to be validation subset
fold <- 10 # 10-fold cross validation
smp1 <- floor(nrow(Healthy_Control_deve)*9/10) 
smp0 <- floor(nrow(Non_Healthy_Control_deve )*9/10) 
# Declare the 'train_ind' and 'corr' variables before using them
Healthy_ControlTrain_ind <- matrix(NA, nrow = fold, ncol = smp1) 
Non_Healthy_Control_ind <- matrix(NA, nrow = fold, ncol = smp0) 

#-Randomly sampling training indices ('train_ind[i,]') for each fold from developing subset
# This is an example to split data into 10 folds. But you can use other splitting approach
for (i in 1:fold){ 
  set.seed(i) # to guarantee repeatable results
  Healthy_ControlTrain_ind[i,] <- sample(seq_len(nrow(Healthy_Control_deve)), size = smp1)
  
  set.seed(i*100)
  Non_Healthy_Control_ind[i,] <- sample(seq_len(nrow(Non_Healthy_Control_deve)), size = smp0)
}

## Step 4: Train a model/classifier on the training subset and valide the classifier on validation seubset by 'fold'-fold cross validation----

# load the "class" library where the knn function is going to be used
#install.packages("class")
library(class) 
# load the "descr" library where the CrossTable function is going to be used
#install.packages("descr")
library(descr)
N <- 20 # suppose we are trying 1~20 nearest neighbours
BA <- matrix(NA, nrow = 1, ncol = fold) # BA: Balanced accuracy for 'fold' folds in terms of a specific k
BA_K <- matrix(NA, nrow = N, ncol = 1)  # BA_K: Store average BA of 'fold' folds for each k

for (k in 1:N)
{
  for (i in 1:fold)
  {
    TrainSubset <- rbind(Healthy_Control_deve[Healthy_ControlTrain_ind[i,],], Non_Healthy_Control_deve[Non_Healthy_Control_ind[i,],])
    ValidSubset <- rbind(Healthy_Control_deve[-Healthy_ControlTrain_ind[i,],], Non_Healthy_Control_deve[-Non_Healthy_Control_ind[i,],])
    # Randomly reorder the elements of the training subset
    set.seed(i*k)
    TrainSubset <- TrainSubset[sample(nrow(TrainSubset)),]
    # Randomly reorder the elements of the validation subset
    set.seed(i*k+100)
    ValidSubset <- ValidSubset[sample(nrow(ValidSubset)),]
    # Train the knn classifier with different k
    valid_pred <- knn(train = TrainSubset[,1:9], test = ValidSubset[,1:9], cl = TrainSubset[,9], k)
    # Get the confusion matrix table
    CT <- CrossTable(x = ValidSubset[,9], y = valid_pred)
    # Calculate balanced accuracy (BA) for each fold
    BA[i] <- (CT$t[1,1]/(CT$t[1,1]+CT$t[1,2]) + CT$t[2,2]/(CT$t[2, 1]+CT$t[2,2]))/2
  }
  # Calculate the mean of BA for each k
  BA_K[k] <- mean(BA)
}

# Find the maximum balanced accuracy with the corresponding k, max_k
max_k <- which.max(BA_K) 
max_k
# Step 5: Test the classifer with trained k (max_k)
DeveSubset <- rbind(Healthy_Control_deve, Non_Healthy_Control_deve) # combining all developing sets
# Randomly reorder the elements of the developing subset
set.seed(12345)
DeveSubset <- DeveSubset[sample(nrow(DeveSubset)),]

deve_pred <- knn(train = DeveSubset[,1:9], test = TestingSubset[,1:9], cl = DeveSubset[,9], max_k)

CT <- CrossTable(x = TestingSubset[,9], y = deve_pred)
BA_Test <- (CT$t[1,1]/(CT$t[1,1]+CT$t[1,2]) + CT$t[2,2]/(CT$t[2, 1]+CT$t[2,2]))/2
CT
table(TestingSubset[,9],deve_pred)


```




